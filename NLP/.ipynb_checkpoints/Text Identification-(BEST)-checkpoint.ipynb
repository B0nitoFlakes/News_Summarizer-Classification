{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec5a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/HP/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/HP/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/HP/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9842449",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e069b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Users/HP/Documents/STUDIES/PYTHONCODES/DATASETS/NewsCategorizer.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffc4e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>links</th>\n",
       "      <th>short_description</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>143 Miles in 35 Days: Lessons Learned</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/running-l...</td>\n",
       "      <td>Resting is part of training. I've confirmed wh...</td>\n",
       "      <td>running-lessons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Talking to Yourself: Crazy or Crazy Helpful?</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/talking-t...</td>\n",
       "      <td>Think of talking to yourself as a tool to coac...</td>\n",
       "      <td>talking-to-yourself-crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Crenezumab: Trial Will Gauge Whether Alzheimer...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/crenezuma...</td>\n",
       "      <td>The clock is ticking for the United States to ...</td>\n",
       "      <td>crenezumab-alzheimers-disease-drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Oh, What a Difference She Made</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/meaningfu...</td>\n",
       "      <td>If you want to be busy, keep trying to be perf...</td>\n",
       "      <td>meaningful-life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Green Superfoods</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/green-sup...</td>\n",
       "      <td>First, the bad news: Soda bread, corned beef a...</td>\n",
       "      <td>green-superfoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>This Baseball Team Learned There's A Wrong Way...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/san-jose-...</td>\n",
       "      <td>Many fans were pissed after seeing the minor l...</td>\n",
       "      <td>san-jose-giants-japanese-heritage-night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Some Young Spurs Fan Dabbed 38 Times In A Sing...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/dab-kid-s...</td>\n",
       "      <td>Never change, young man. Never change.</td>\n",
       "      <td>dab-kid-san-antonio-spurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Rasheed Wallace Ejected From Knicks-Suns Game ...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/rasheed-w...</td>\n",
       "      <td>Wallace was hit with a first technical for a h...</td>\n",
       "      <td>rasheed-wallace-ejected-knicks-suns-ball-dont-lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Why Jake Plummer And Other NFL Players Are Pus...</td>\n",
       "      <td>https://www.huffingtonpost.comhttp://extras.de...</td>\n",
       "      <td>They believe CBD could be an alternative to po...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Simone Biles Isn't The Next Anyone, She's 'The...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/the-first...</td>\n",
       "      <td>The gymnast is in a league of her own.</td>\n",
       "      <td>the-first-simone-biles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                           headline  \\\n",
       "0      WELLNESS              143 Miles in 35 Days: Lessons Learned   \n",
       "1      WELLNESS       Talking to Yourself: Crazy or Crazy Helpful?   \n",
       "2      WELLNESS  Crenezumab: Trial Will Gauge Whether Alzheimer...   \n",
       "3      WELLNESS                     Oh, What a Difference She Made   \n",
       "4      WELLNESS                                   Green Superfoods   \n",
       "...         ...                                                ...   \n",
       "49995    SPORTS  This Baseball Team Learned There's A Wrong Way...   \n",
       "49996    SPORTS  Some Young Spurs Fan Dabbed 38 Times In A Sing...   \n",
       "49997    SPORTS  Rasheed Wallace Ejected From Knicks-Suns Game ...   \n",
       "49998    SPORTS  Why Jake Plummer And Other NFL Players Are Pus...   \n",
       "49999    SPORTS  Simone Biles Isn't The Next Anyone, She's 'The...   \n",
       "\n",
       "                                                   links  \\\n",
       "0      https://www.huffingtonpost.com/entry/running-l...   \n",
       "1      https://www.huffingtonpost.com/entry/talking-t...   \n",
       "2      https://www.huffingtonpost.com/entry/crenezuma...   \n",
       "3      https://www.huffingtonpost.com/entry/meaningfu...   \n",
       "4      https://www.huffingtonpost.com/entry/green-sup...   \n",
       "...                                                  ...   \n",
       "49995  https://www.huffingtonpost.com/entry/san-jose-...   \n",
       "49996  https://www.huffingtonpost.com/entry/dab-kid-s...   \n",
       "49997  https://www.huffingtonpost.com/entry/rasheed-w...   \n",
       "49998  https://www.huffingtonpost.comhttp://extras.de...   \n",
       "49999  https://www.huffingtonpost.com/entry/the-first...   \n",
       "\n",
       "                                       short_description  \\\n",
       "0      Resting is part of training. I've confirmed wh...   \n",
       "1      Think of talking to yourself as a tool to coac...   \n",
       "2      The clock is ticking for the United States to ...   \n",
       "3      If you want to be busy, keep trying to be perf...   \n",
       "4      First, the bad news: Soda bread, corned beef a...   \n",
       "...                                                  ...   \n",
       "49995  Many fans were pissed after seeing the minor l...   \n",
       "49996             Never change, young man. Never change.   \n",
       "49997  Wallace was hit with a first technical for a h...   \n",
       "49998  They believe CBD could be an alternative to po...   \n",
       "49999             The gymnast is in a league of her own.   \n",
       "\n",
       "                                                keywords  \n",
       "0                                        running-lessons  \n",
       "1                              talking-to-yourself-crazy  \n",
       "2                     crenezumab-alzheimers-disease-drug  \n",
       "3                                        meaningful-life  \n",
       "4                                       green-superfoods  \n",
       "...                                                  ...  \n",
       "49995            san-jose-giants-japanese-heritage-night  \n",
       "49996                          dab-kid-san-antonio-spurs  \n",
       "49997  rasheed-wallace-ejected-knicks-suns-ball-dont-lie  \n",
       "49998                                                NaN  \n",
       "49999                             the-first-simone-biles  \n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926d85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   category           50000 non-null  object\n",
      " 1   headline           50000 non-null  object\n",
      " 2   links              50000 non-null  object\n",
      " 3   short_description  50000 non-null  object\n",
      " 4   keywords           47332 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ffe38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns=['headline', 'links', 'keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f9817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['description'] = df1['short_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "881fd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns=['short_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9280220d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Resting is part of training. I've confirmed wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Think of talking to yourself as a tool to coac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>The clock is ticking for the United States to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>If you want to be busy, keep trying to be perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>First, the bad news: Soda bread, corned beef a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Many fans were pissed after seeing the minor l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Never change, young man. Never change.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Wallace was hit with a first technical for a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>They believe CBD could be an alternative to po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>The gymnast is in a league of her own.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                        description\n",
       "0      WELLNESS  Resting is part of training. I've confirmed wh...\n",
       "1      WELLNESS  Think of talking to yourself as a tool to coac...\n",
       "2      WELLNESS  The clock is ticking for the United States to ...\n",
       "3      WELLNESS  If you want to be busy, keep trying to be perf...\n",
       "4      WELLNESS  First, the bad news: Soda bread, corned beef a...\n",
       "...         ...                                                ...\n",
       "49995    SPORTS  Many fans were pissed after seeing the minor l...\n",
       "49996    SPORTS             Never change, young man. Never change.\n",
       "49997    SPORTS  Wallace was hit with a first technical for a h...\n",
       "49998    SPORTS  They believe CBD could be an alternative to po...\n",
       "49999    SPORTS             The gymnast is in a league of her own.\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6733cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/HP/Documents/STUDIES/PYTHONCODES/DATASETS/news_category1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d99f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5471365a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepMind's AI system 'AlphaFold' has been reco...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Teams will stop working on Internet ...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China, in response to reports of US adding Chi...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The global smartphone sales in the third quart...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The European Union (EU) is hoping that US Pres...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Many fans were pissed after seeing the minor l...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Never change, young man. Never change.</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Wallace was hit with a first technical for a h...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>They believe CBD could be an alternative to po...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>The gymnast is in a league of her own.</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description    category\n",
       "0      DeepMind's AI system 'AlphaFold' has been reco...  TECHNOLOGY\n",
       "1      Microsoft Teams will stop working on Internet ...  TECHNOLOGY\n",
       "2      China, in response to reports of US adding Chi...  TECHNOLOGY\n",
       "3      The global smartphone sales in the third quart...  TECHNOLOGY\n",
       "4      The European Union (EU) is hoping that US Pres...  TECHNOLOGY\n",
       "...                                                  ...         ...\n",
       "49995  Many fans were pissed after seeing the minor l...      SPORTS\n",
       "49996             Never change, young man. Never change.      SPORTS\n",
       "49997  Wallace was hit with a first technical for a h...      SPORTS\n",
       "49998  They believe CBD could be an alternative to po...      SPORTS\n",
       "49999             The gymnast is in a league of her own.      SPORTS\n",
       "\n",
       "[62120 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df32fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    China, in response to reports of US adding Chi...\n",
       "2    The clock is ticking for the United States to ...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.description[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87989c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepMind's AI system 'AlphaFold' has been reco...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Teams will stop working on Internet ...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China, in response to reports of US adding Chi...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The global smartphone sales in the third quart...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The European Union (EU) is hoping that US Pres...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49988</th>\n",
       "      <td>Monday’s events beg the question -- would a bl...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>Plenty of air, plenty to do</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Many fans were pissed after seeing the minor l...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Never change, young man. Never change.</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>The gymnast is in a league of her own.</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51165 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description    category\n",
       "0      DeepMind's AI system 'AlphaFold' has been reco...  TECHNOLOGY\n",
       "1      Microsoft Teams will stop working on Internet ...  TECHNOLOGY\n",
       "2      China, in response to reports of US adding Chi...  TECHNOLOGY\n",
       "3      The global smartphone sales in the third quart...  TECHNOLOGY\n",
       "4      The European Union (EU) is hoping that US Pres...  TECHNOLOGY\n",
       "...                                                  ...         ...\n",
       "49988  Monday’s events beg the question -- would a bl...      SPORTS\n",
       "49991                        Plenty of air, plenty to do      SPORTS\n",
       "49995  Many fans were pissed after seeing the minor l...      SPORTS\n",
       "49996             Never change, young man. Never change.      SPORTS\n",
       "49999             The gymnast is in a league of her own.      SPORTS\n",
       "\n",
       "[51165 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e06b05a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "ENTERTAINMENT     7036\n",
       "SPORTS            6900\n",
       "POLITICS          6596\n",
       "WELLNESS          5000\n",
       "TRAVEL            5000\n",
       "STYLE & BEAUTY    5000\n",
       "PARENTING         5000\n",
       "FOOD & DRINK      5000\n",
       "WORLD NEWS        5000\n",
       "BUSINESS          5000\n",
       "WORLD             2067\n",
       "TECHNOLOGY        1791\n",
       "SCIENCE           1437\n",
       "AUTOMOBILE        1293\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0600f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    TECHNOLOGY\n",
      "1      WELLNESS\n",
      "Name: category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Access rows based on the original integer-based index\n",
    "print(final_df.loc[1]['category'])  # Accessing the first row with index 1\n",
    "\n",
    "# Reset the index of your DataFrame\n",
    "final_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3a5eb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "WORLD             7067\n",
      "ENTERTAINMENT     7036\n",
      "SPORTS            6900\n",
      "POLITICS          6596\n",
      "WELLNESS          5000\n",
      "TRAVEL            5000\n",
      "STYLE & BEAUTY    5000\n",
      "PARENTING         5000\n",
      "FOOD & DRINK      5000\n",
      "BUSINESS          5000\n",
      "TECHNOLOGY        1791\n",
      "SCIENCE           1437\n",
      "AUTOMOBILE        1293\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace 'WORLD NEWS' with 'WORLD' in the 'category' column\n",
    "final_df['category'] = final_df['category'].replace('WORLD NEWS', 'WORLD')\n",
    "\n",
    "# Verify the updated category counts\n",
    "category_counts = final_df['category'].value_counts()\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e672f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rows_per_category = 1000\n",
    "\n",
    "selected_data = pd.DataFrame(columns=['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de00a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate over each category and select the desired number of rows\n",
    "for category, count in final_df['category'].value_counts().items():\n",
    "    if count >= target_rows_per_category:\n",
    "        # Select the first 2000 rows for the category\n",
    "        category_data = final_df[final_df['category'] == category].head(target_rows_per_category)\n",
    "        selected_data = pd.concat([selected_data, category_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa0c1302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "WORLD             1000\n",
       "ENTERTAINMENT     1000\n",
       "SPORTS            1000\n",
       "POLITICS          1000\n",
       "WELLNESS          1000\n",
       "TRAVEL            1000\n",
       "STYLE & BEAUTY    1000\n",
       "PARENTING         1000\n",
       "FOOD & DRINK      1000\n",
       "BUSINESS          1000\n",
       "TECHNOLOGY        1000\n",
       "SCIENCE           1000\n",
       "AUTOMOBILE        1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39bdf946",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba8b8787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        A 101-year-old Italian woman who lived through...\n",
       "1        China on February 10 officially reported 2,478...\n",
       "2        A US analyst has said North Korean leader Kim ...\n",
       "3        Commenting on farmers' protests in India durin...\n",
       "4        According to WHO's latest World Malaria Report...\n",
       "                               ...                        \n",
       "12995    Kapil Sharma has been summoned by Mumbai Polic...\n",
       "12996    General Motors has unveiled a Cadillac-branded...\n",
       "12997    Elon Musk has tweeted \"as promised\" in respons...\n",
       "12998    Tesla has named Vaibhav Taneja, David Jon Fein...\n",
       "12999    Tesla has marked its entry in India and regist...\n",
       "Name: description, Length: 13000, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f22954c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'SPORTS': 1,\n",
    "    'BUSINESS': 2,\n",
    "    'WELLNESS': 3,\n",
    "    'POLITICS': 4,\n",
    "    'ENTERTAINMENT': 5,\n",
    "    'TRAVEL': 6,\n",
    "    'STYLE & BEAUTY': 7,\n",
    "    'PARENTING': 8,\n",
    "    'FOOD & DRINK': 9,\n",
    "    'WORLD': 10,\n",
    "    'TECHNOLOGY': 11,\n",
    "    'SCIENCE': 12,\n",
    "    'AUTOMOBILE': 13,\n",
    "}\n",
    "\n",
    "# Create a new \"category_id\" column based on the mapping\n",
    "selected_data['category_id'] = selected_data['category'].map(category_mapping)\n",
    "\n",
    "# Sort the DataFrame by the \"category_id\" column\n",
    "selected_data = selected_data.sort_values(by='category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9da500bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'SPORTS': 1,\n",
    "    'BUSINESS': 2,\n",
    "    'WELLNESS': 3,\n",
    "    'POLITICS': 4,\n",
    "    'ENTERTAINMENT': 5,\n",
    "    'TRAVEL': 6,\n",
    "    'STYLE & BEAUTY': 7,\n",
    "    'PARENTING': 8,\n",
    "    'FOOD & DRINK': 9,\n",
    "    'WORLD': 10,\n",
    "    'TECHNOLOGY': 11,\n",
    "    'SCIENCE': 12,\n",
    "    'AUTOMOBILE': 13,\n",
    "}\n",
    "\n",
    "# Create a new \"category_id\" column based on the mapping\n",
    "final_df['category_id'] = final_df['category'].map(category_mapping)\n",
    "\n",
    "# Sort the DataFrame by the \"category_id\" column\n",
    "final_df = final_df.sort_values(by='category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c07c204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62119</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56752</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15354</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21352</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26387</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31592</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36594</th>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41594</th>\n",
       "      <td>PARENTING</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46528</th>\n",
       "      <td>FOOD &amp; DRINK</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47176</th>\n",
       "      <td>WORLD</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9833</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  category_id\n",
       "62119          SPORTS            1\n",
       "56752        BUSINESS            2\n",
       "15354        WELLNESS            3\n",
       "21352        POLITICS            4\n",
       "26387   ENTERTAINMENT            5\n",
       "31592          TRAVEL            6\n",
       "36594  STYLE & BEAUTY            7\n",
       "41594       PARENTING            8\n",
       "46528    FOOD & DRINK            9\n",
       "47176           WORLD           10\n",
       "570        TECHNOLOGY           11\n",
       "9833          SCIENCE           12\n",
       "142        AUTOMOBILE           13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_list = final_df[['category', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9730a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_colors = {\n",
    "#     1: \"pink\",\n",
    "#     2: \"orange\",\n",
    "#     3: \"red\",\n",
    "#     4: \"yellow\",\n",
    "#     5: \"blue\",\n",
    "#     6: \"green\",\n",
    "#     7: \"lightblue\",\n",
    "#     8: \"purple\",\n",
    "#     9: \"gray\",\n",
    "#     10: \"brown\"\n",
    "#     11: \"black\"\n",
    "# }\n",
    "\n",
    "# df1.groupby('category').category_id.value_counts().plot(kind = \"bar\", color=[category_colors[cat_id] for cat_id in category_counts['category_id']])\n",
    "# plt.xlabel(\"Category of data\")\n",
    "# plt.title(\"Visulaize numbers of Category of data\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb5bce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adb1f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# sports = df1[df1['category_id'] == 1]\n",
    "\n",
    "# sports = sports['short_description']\n",
    "\n",
    "business = df1[df1['category_id'] == 2]\n",
    "\n",
    "business = business['short_description']\n",
    "\n",
    "wellness = df1[df1['category_id'] == 3]\n",
    "\n",
    "wellness = wellness['short_description']\n",
    "\n",
    "politics = df1[df1['category_id'] == 4]\n",
    "\n",
    "politics = politics['short_description']\n",
    "\n",
    "entertainment = df1[df1['category_id'] == 5]\n",
    "\n",
    "entertainment = entertainment['short_description']\n",
    "\n",
    "travel = df1[df1['category_id'] == 6]\n",
    "\n",
    "travel = travel['short_description']\n",
    "\n",
    "styleandbeauty = df1[df1['category_id'] == 7]\n",
    "\n",
    "styleandbeauty = styleandbeauty['short_description']\n",
    "\n",
    "parenting = df1[df1['category_id'] == 8]\n",
    "\n",
    "parenting = parenting['short_description']\n",
    "\n",
    "foodanddrink = df1[df1['category_id'] == 9]\n",
    "\n",
    "foodanddrink = foodanddrink['short_description']\n",
    "\n",
    "world = df1[df1['category_id'] == 10]\n",
    "\n",
    "world = world['short_description']\n",
    "\n",
    "tecnology = df1[df1['category_id'] == 11]\n",
    "\n",
    "technology = technology['short_description']\n",
    "\n",
    "science = df1[df1['category_id'] == 12]\n",
    "\n",
    "science = science['short_description']\n",
    "\n",
    "automobile = df1[df1['category_id'] == 13]\n",
    "\n",
    "automobile = automobile['short_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3db52f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wordcloud_draw(dataset, color = 'white'):\n",
    "\n",
    "#     words = ' '.join(dataset)\n",
    "\n",
    "#     cleaned_word = ' '.join([word for word in words.split()\n",
    "\n",
    "#     if (word != 'news' and word != 'short_description')])\n",
    "\n",
    "#     wordcloud = WordCloud(stopwords = stop,\n",
    "\n",
    "#     background_color = color,\n",
    "\n",
    "#     width = 2500, height = 2500).generate(cleaned_word)\n",
    "        \n",
    "\n",
    "#     plt.figure(1, figsize = (10,7))\n",
    "\n",
    "#     plt.imshow(wordcloud)\n",
    "\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af001923",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"sport related words:\")\n",
    "\n",
    "# wordcloud_draw(sports, 'white')\n",
    "\n",
    "# print(\"business related words:\")\n",
    "\n",
    "# wordcloud_draw(business, 'white')\n",
    "\n",
    "# print(\"wellness related words:\")\n",
    "\n",
    "# wordcloud_draw(wellness, 'white')\n",
    "\n",
    "# print(\"politics related words:\")\n",
    "\n",
    "# wordcloud_draw(politics, 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e08147b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = df1['short_description']\n",
    "# print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53d11575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = df1['category']\n",
    "# category.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d27e44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Tags\n",
    "\n",
    "def remove_tags(text):\n",
    "  remove = re.compile(r'<.*?>')\n",
    "  return re.sub(remove, '', text)\n",
    "final_df['description'] = final_df['description'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb16c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special Character removal\n",
    "\n",
    "def special_char(text):\n",
    "  reviews = ''\n",
    "  for x in text:\n",
    "    if x.isalnum():\n",
    "      reviews = reviews + x\n",
    "    else:\n",
    "      reviews = reviews + ' '\n",
    "  return reviews\n",
    "final_df['description'] = final_df['description'].apply(special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18caff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft teams will stop working on internet explorer 11 from today  november 30  users will now need to download the teams app or browse it on microsoft edge  besides this  microsoft 365 apps and services will stop supporting internet explorer 11 by august 2021  microsoft will also pull support for microsoft edge legacy desktop app on march 9 \n"
     ]
    }
   ],
   "source": [
    "#Lowercasing\n",
    "\n",
    "def convert_lower(text):\n",
    "   return text.lower()\n",
    "final_df['description'] = final_df['description'].apply(convert_lower)\n",
    "\n",
    "\n",
    "print(final_df['description'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "443019a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microsoft', 'teams', 'stop', 'working', 'internet', 'explorer', '11', 'today', 'november', '30', 'users', 'need', 'download', 'teams', 'app', 'browse', 'microsoft', 'edge', 'besides', 'microsoft', '365', 'apps', 'services', 'stop', 'supporting', 'internet', 'explorer', '11', 'august', '2021', 'microsoft', 'also', 'pull', 'support', 'microsoft', 'edge', 'legacy', 'desktop', 'app', 'march', '9']\n"
     ]
    }
   ],
   "source": [
    "#Stopwords removal\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  words = word_tokenize(text)\n",
    "  return [x for x in words if x not in stop_words]\n",
    "final_df['description'] = final_df['description'].apply(remove_stopwords)\n",
    "\n",
    "\n",
    "print(final_df['description'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb16b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft team stop working internet explorer 11 today november 30 user need download team app browse microsoft edge besides microsoft 365 apps service stop supporting internet explorer 11 august 2021 microsoft also pull support microsoft edge legacy desktop app march 9\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "\n",
    "def lemmatize_word(text):\n",
    "  wordnet = WordNetLemmatizer()\n",
    "  return \" \".join([wordnet.lemmatize(word) for word in text])\n",
    "final_df['description'] = final_df['description'].apply(lemmatize_word)\n",
    "# Access and print the lemmatized 'short_description' of the first row\n",
    "print(final_df['description'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62db6fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2998     ex australia captain allan border belief pacer...\n",
      "2339     csk rounder ravindra jadeja smashed two six la...\n",
      "2338     csk ravindra jadeja thursday became fifth indi...\n",
      "2337     rajasthan royal chased 186 run target king xi ...\n",
      "2336     kxip batsman chris gayle threw away bat frustr...\n",
      "                               ...                        \n",
      "12338    baidu become first receive permit beijing tran...\n",
      "12339    road transport highway minister nitin gadkari ...\n",
      "12340    tesla ceo elon musk sent email worker encourag...\n",
      "12327    volkswagen ceo herbert dy blog post revealed o...\n",
      "12999    tesla marked entry india registered company be...\n",
      "Name: description, Length: 13000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "selected_data['description'] = selected_data['description'].apply(remove_tags)\n",
    "selected_data['description'] = selected_data['description'].apply(special_char)\n",
    "selected_data['description'] = selected_data['description'].apply(convert_lower)\n",
    "selected_data['description'] = selected_data['description'].apply(remove_stopwords)\n",
    "selected_data['description'] = selected_data['description'].apply(lemmatize_word)\n",
    "\n",
    "print(selected_data['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db306b",
   "metadata": {},
   "source": [
    "# Using final_df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c826d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the Input features and target\n",
    "\n",
    "# x = final_df['description']\n",
    "# y = final_df['category_id']\n",
    "\n",
    "x = final_df['description']\n",
    "y = final_df['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b0a95c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (62120, 7000)\n",
      "y.shape = (62120,)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'final_df' contains your dataset\n",
    "\n",
    "x = np.array(final_df.iloc[:,0].values)\n",
    "y = np.array(final_df.category_id.values)\n",
    "\n",
    "# Create a TF-IDF vectorizer with a maximum of 6000 features\n",
    "tfidf = TfidfVectorizer(max_features=7000)\n",
    "\n",
    "# Transform the text data using TF-IDF vectorization\n",
    "x = tfidf.fit_transform(final_df.description).toarray()\n",
    "\n",
    "print(\"x.shape =\", x.shape)\n",
    "print(\"y.shape =\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "190887c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Bag of Words\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# x = np.array(final_df.iloc[:,0].values)\n",
    "# y = np.array(final_df.category_id.values)\n",
    "# cv = CountVectorizer(max_features = 8000)\n",
    "# x = cv.fit_transform(final_df.description).toarray()\n",
    "# print(\"X.shape = \",x.shape)\n",
    "# print(\"y.shape = \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef3548e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49696\n",
      "12424\n"
     ]
    }
   ],
   "source": [
    "#Split the data into train and test\n",
    "\n",
    "#TF-IDF\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0, shuffle = True)\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "\n",
    "# #Count Vectorizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0, shuffle = True)\n",
    "# print(len(x_train))\n",
    "# print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9202fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMEMBER NEED TO DO HYPERPARAMETER TUNING AND TRY TO BALANCE OUT THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6db63",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ae661fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Decision Tree Classifier: % 60.92\n",
      "Precision: 0.6092240824211204\n",
      "Recall: 0.6092240824211204\n",
      "F1-score: 0.6092240824211204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create and fit the Decision Tree classifier\n",
    "mdl1 = DecisionTreeClassifier(random_state=42)\n",
    "mdl1.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mdl1.predict(x_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test Accuracy Score of Decision Tree Classifier: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4894cf",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffc137ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Multinomial Naive Bayes: % 69.16\n",
      "Precision: 0.6916452028332261\n",
      "Recall: 0.6916452028332261\n",
      "F1-score: 0.6916452028332261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create and fit the Multinomial Naive Bayes classifier\n",
    "mdl2 = MultinomialNB()\n",
    "mdl2.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mdl2.predict(x_test)\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test Accuracy Score of Multinomial Naive Bayes: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85177921",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "434ee61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Logistic Regression: % 71.4\n",
      "Precision: 0.7140212491951062\n",
      "Recall: 0.7140212491951062\n",
      "F1-score: 0.7140212491951062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create and fit the Logistic Regression classifier\n",
    "mdl3 = LogisticRegression(random_state=42)\n",
    "mdl3.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mdl3.predict(x_test)\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test Accuracy Score of Logistic Regression: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc033d",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e2baf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Random Forest: % 67.31\n",
      "Precision: 0.6731326464906632\n",
      "Recall: 0.6731326464906632\n",
      "F1-score: 0.6731326464906632\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the Random Forest classifier\n",
    "\n",
    "mdl = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42)\n",
    "mdl.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mdl.predict(x_test)\n",
    "\n",
    "# Performance metrics\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "\n",
    "# Get precision, recall, and F1-score\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test Accuracy Score of Random Forest: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880bacbb",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e7669f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.07884615        nan 0.51567308 0.25298077 0.07884615        nan\n",
      " 0.71576923 0.69653846 0.49990385        nan 0.77115385 0.77384615\n",
      " 0.74701923        nan 0.80932692 0.81201923 0.79163462        nan\n",
      " 0.81730769 0.81519231 0.78269231        nan 0.80413462 0.80288462]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Test Accuracy Score of Logistic Regression after Hyperparameter Tuning: % 82.62\n",
      "Precision: 0.8261538461538461\n",
      "Recall: 0.8261538461538461\n",
      "F1-score: 0.8261538461538461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Define the hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Perform Grid Search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(mdl3, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the best estimator\n",
    "y_pred = best_estimator.predict(x_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# Print the results\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Test Accuracy Score of Logistic Regression after Hyperparameter Tuning: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c5c63",
   "metadata": {},
   "source": [
    "# Predictions - final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccb80e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city diverse highly dynamic system analysis planning control kind complex system simulation frequently used cope vast complexity city even small district simulation model usually focus distinct spatial functional subsystem paper city planning gaming software analyzed modified evaluated regarding potential application simulation urban production modelling real city district comprehensive simulation based understanding influence urban factory urban surrounding vice versa allows environmental economic social beneficial value creation livable city quarter\n"
     ]
    }
   ],
   "source": [
    "prediction_texts = \"\"\"Cities are very diverse and highly dynamic systems. For analysis, planning and control of those kind of complex systems, simulation is frequently\n",
    "used. To cope with the vast complexity of a city or even a small district, simulation models usually focus on distinct spatial and functional\n",
    "subsystems. In this paper, city-planning gaming software is analyzed, modified and evaluated regarding its potential for application in simulation\n",
    "of urban production while modelling a real city district. A comprehensive, simulation-based understanding of the influences of urban factories\n",
    "on their urban surrounding and vice versa allows a more environmental, economic and social beneficial value creation and more livable city\n",
    "quarters.””\"\"\"\n",
    "\n",
    "prediction_texts = remove_tags(prediction_texts)\n",
    "prediction_texts = special_char(prediction_texts)\n",
    "prediction_texts = convert_lower(prediction_texts)\n",
    "prediction_texts = remove_stopwords(prediction_texts)\n",
    "prediction_texts = lemmatize_word(prediction_texts)\n",
    "\n",
    "print(prediction_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c71d8af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel News\n"
     ]
    }
   ],
   "source": [
    "#Predict the input text\n",
    "\n",
    "y_pred1 = tfidf.transform([prediction_texts])\n",
    "\n",
    "\n",
    "yy = best_estimator.predict(y_pred1)\n",
    "result = \"\"\n",
    "if yy == [1]:\n",
    "  result = \"Sports News\"\n",
    "elif yy == [2]:\n",
    "  result = \"Business News\"\n",
    "elif yy == [3]:\n",
    "  result = \"Wellness News\"\n",
    "elif yy == [4]:\n",
    "  result = \"Politics News\"\n",
    "elif yy == [5]:\n",
    "  result = \"Entertainment News\"\n",
    "elif yy == [6]:\n",
    "  result = \"Travel News\"\n",
    "elif yy == [7]:\n",
    "  result = \"Style and Beauty News\"\n",
    "elif yy == [8]:\n",
    "  result = \"Parenting News\"\n",
    "elif yy == [9]:\n",
    "  result = \"Food and Drink News\"\n",
    "elif yy == [10]:\n",
    "  result = \"World News\"\n",
    "elif yy == [11]:\n",
    "  result = \"Technology News\"\n",
    "elif yy == [12]:\n",
    "  result = \"Science News\"\n",
    "elif yy == [13]:\n",
    "  result = \"Automobile News\"\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b3b5",
   "metadata": {},
   "source": [
    "# Using selected_data as the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d937625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the Input features and target\n",
    "\n",
    "X = selected_data['description']\n",
    "Y = selected_data['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a89a9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (13000, 7000)\n",
      "y.shape = (13000,)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'final_df' contains your dataset\n",
    "\n",
    "X = np.array(selected_data.iloc[:,0].values)\n",
    "Y = np.array(selected_data.category_id.values)\n",
    "\n",
    "# Create a TF-IDF vectorizer with a maximum of 6000 features\n",
    "tfidf = TfidfVectorizer(max_features=7000)\n",
    "\n",
    "# Transform the text data using TF-IDF vectorization\n",
    "X = tfidf.fit_transform(selected_data.description).toarray()\n",
    "\n",
    "print(\"x.shape =\", X.shape)\n",
    "print(\"y.shape =\",Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7243c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400\n",
      "2600\n"
     ]
    }
   ],
   "source": [
    "#Split the data into train and test\n",
    "\n",
    "#TF-IDF\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0, shuffle = True)\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7957a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Decision Tree Classifier: % 75.58\n",
      "Precision: 0.7557692307692307\n",
      "Recall: 0.7557692307692307\n",
      "F1-score: 0.7557692307692307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create and fit the Decision Tree classifier\n",
    "mdl1 = DecisionTreeClassifier(random_state=42)\n",
    "mdl1.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mdl1.predict(x_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test Accuracy Score of Decision Tree Classifier: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d228df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Multinomial Naive Bayes: % 79.85\n",
      "Precision: 0.7984615384615384\n",
      "Recall: 0.7984615384615384\n",
      "F1-score: 0.7984615384615384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create and fit the Multinomial Naive Bayes classifier\n",
    "mdl2 = MultinomialNB()\n",
    "mdl2.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mdl2.predict(x_test)\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test Accuracy Score of Multinomial Naive Bayes: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98077cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Logistic Regression: % 82.15\n",
      "Precision: 0.8215384615384616\n",
      "Recall: 0.8215384615384616\n",
      "F1-score: 0.8215384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create and fit the Logistic Regression classifier\n",
    "mdl5 = LogisticRegression(random_state=42)\n",
    "mdl5.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mdl5.predict(x_test)\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test Accuracy Score of Logistic Regression: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0bb1107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Random Forest: % 80.15\n",
      "Precision: 0.8015384615384615\n",
      "Recall: 0.8015384615384615\n",
      "F1-score: 0.8015384615384614\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the Random Forest classifier\n",
    "\n",
    "mdl = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=42)\n",
    "mdl.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mdl.predict(x_test)\n",
    "\n",
    "# Performance metrics\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "\n",
    "# Get precision, recall, and F1-score\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test Accuracy Score of Random Forest: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65daefac",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ec7e845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/HP/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.07884615        nan 0.51567308 0.25298077 0.07884615        nan\n",
      " 0.71576923 0.69653846 0.49990385        nan 0.77115385 0.77384615\n",
      " 0.74701923        nan 0.80932692 0.81201923 0.79163462        nan\n",
      " 0.81730769 0.81519231 0.78269231        nan 0.80413462 0.80288462]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Test Accuracy Score of Logistic Regression after Hyperparameter Tuning: % 82.62\n",
      "Precision: 0.8261538461538461\n",
      "Recall: 0.8261538461538461\n",
      "F1-score: 0.8261538461538461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Perform Grid Search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(mdl5, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimatorss = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the best estimator\n",
    "y_pred = best_estimatorss.predict(x_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# Print the results\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Test Accuracy Score of Logistic Regression after Hyperparameter Tuning: % {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201aaa2f",
   "metadata": {},
   "source": [
    "# Predictions - selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e9376e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hong kong singer pakho chau appears made substantial sum performance wedding shenzhen china according oriental daily chau paid 700 000 yuan rm455 178 sing two song vow best report added bride ardent fan singer multiple video chau 38 performing ceremony uploaded online clip cantopop star elegantly dressed suit seen greeting guest interacting audience throughout performance several social medium user present ceremony also took weibo share experience many noting chau cordial behaviour shook hand guest belting track onstage many said money spent invite chau worth others deemed pricey two song hk01 reported hong kong television presenter bob lam served event emcee report added lam 44 reportedly charge six figure sum per hosting session first time someone forked hundred thousand invite celebrity perform host\n"
     ]
    }
   ],
   "source": [
    "prediction_texts = \"\"\"Hong Kong singer Pakho Chau appears to have made a substantial sum from his performance at a wedding in Shenzhen, China.\n",
    "\n",
    "According to Oriental Daily, Chau was paid 700,000 yuan (RM455,178) to sing two songs – My Vow and The Best. The report added that the bride was an ardent fan of the singer.\n",
    "\n",
    "Multiple videos of Chau, 38, performing at the ceremony have been uploaded on online. In the clips, the Cantopop star – elegantly dressed in a suit – can be seen greeting guests and interacting with the audience throughout his performance.\n",
    "\n",
    "Several social media users who were present at the ceremony also took to Weibo to share their experience, with many noting Chau's cordial behaviour as he shook hands with guests while belting out the tracks onstage.\n",
    "\n",
    "While many said the money spent to invite Chau was worth it, others deemed it to be \"too pricey\" for only two songs.\n",
    "\n",
    "HK01 reported that Hong Kong television presenter Bob Lam served as the event's emcee. The report added that Lam, 44, reportedly charges a six-figure sum per hosting session.\n",
    "\n",
    "This isn't the first time someone has forked out hundreds of thousands to invite celebrities to perform or host for them.\"\"\"\n",
    "\n",
    "prediction_texts = remove_tags(prediction_texts)\n",
    "prediction_texts = special_char(prediction_texts)\n",
    "prediction_texts = convert_lower(prediction_texts)\n",
    "prediction_texts = remove_stopwords(prediction_texts)\n",
    "prediction_texts = lemmatize_word(prediction_texts)\n",
    "\n",
    "print(prediction_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67e3baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entertainment News\n"
     ]
    }
   ],
   "source": [
    "#Predict the input text\n",
    "\n",
    "y_pred1 = tfidf.transform([prediction_texts])\n",
    "\n",
    "\n",
    "yy = best_estimatorss.predict(y_pred1)\n",
    "result = \"\"\n",
    "if yy == [1]:\n",
    "  result = \"Sports News\"\n",
    "elif yy == [2]:\n",
    "  result = \"Business News\"\n",
    "elif yy == [3]:\n",
    "  result = \"Wellness News\"\n",
    "elif yy == [4]:\n",
    "  result = \"Politics News\"\n",
    "elif yy == [5]:\n",
    "  result = \"Entertainment News\"\n",
    "elif yy == [6]:\n",
    "  result = \"Travel News\"\n",
    "elif yy == [7]:\n",
    "  result = \"Style and Beauty News\"\n",
    "elif yy == [8]:\n",
    "  result = \"Parenting News\"\n",
    "elif yy == [9]:\n",
    "  result = \"Food and Drink News\"\n",
    "elif yy == [10]:\n",
    "  result = \"World News\"\n",
    "elif yy == [11]:\n",
    "  result = \"Technology News\"\n",
    "elif yy == [12]:\n",
    "  result = \"Science News\"\n",
    "elif yy == [13]:\n",
    "  result = \"Automobile News\"\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45a55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
