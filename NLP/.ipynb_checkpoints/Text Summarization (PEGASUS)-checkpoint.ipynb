{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f72b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4844f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input_length=512, max_output_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        article = self.data.iloc[index][\"article\"]\n",
    "        summary = self.data.iloc[index][\"highlights\"]\n",
    "        input_ids = self.tokenizer.encode(article, max_length=self.max_input_length, truncation=True, padding=\"max_length\")\n",
    "        output_ids = self.tokenizer.encode(summary, max_length=self.max_output_length, truncation=True, padding=\"max_length\")\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": [int(token_id != 0) for token_id in input_ids], \"decoder_input_ids\": output_ids[:-1], \"decoder_attention_mask\": [1] * (len(output_ids) - 1), \"labels\": output_ids[1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1b0d98",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/HP/Documents/PYTHONCODES/DATASETS/cnn_dailymail/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/HP/Documents/PYTHONCODES/DATASETS/cnn_dailymail/train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/HP/Documents/PYTHONCODES/DATASETS/cnn_dailymail/test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m val_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/HP/Documents/PYTHONCODES/DATASETS/cnn_dailymail/validation.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/HP/Documents/PYTHONCODES/DATASETS/cnn_dailymail/train.csv'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/Users/HP/Documents/PYTHONCODES/DATASETS/cnn_dailymail/train.csv\")\n",
    "test_df = pd.read_csv(\"/Users/HP/Documents/PYTHONCODES/DATASETS/cnn_dailymail/test.csv\")\n",
    "val_df = pd.read_csv(\"/Users/HP/Documents/PYTHONCODES/DATASETS/cnn_dailymail/validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b45fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SummarizationDataset(train_df, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ae8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    decoder_input_ids = [item[\"decoder_input_ids\"] for item in batch]\n",
    "    decoder_attention_mask = [item[\"decoder_attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    max_input_length = max(len(ids) for ids in input_ids)\n",
    "    max_output_length = max(len(ids) for ids in decoder_input_ids)\n",
    "    input_ids = [ids + [0] * (max_input_length - len(ids)) for ids in input_ids]\n",
    "    attention_mask = [mask + [0] * (max_input_length - len(mask)) for mask in attention_mask]\n",
    "    decoder_input_ids = [ids + [0] * (max_output_length - len(ids)) for ids in decoder_input_ids]\n",
    "    decoder_attention_mask = [mask + [0] * (max_output_length - len(mask)) for mask in decoder_attention_mask]\n",
    "    labels = [ids + [-100] * (max_output_length - len(ids)) for ids in labels]\n",
    "    return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ee408",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99762dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader),len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    train_loss = 0\n",
    "    for step,batch in tqdm(enumerate(train_loader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss = model(**batch).loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step%300==0 and step>0:\n",
    "            print(\"Step-{},Train Loss-{}\".format(step,loss.item()))\n",
    "            break#intentionally breaking the training after 100 steps since it's going to take long to train,feel free to comment and train more\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step,batch in tqdm(enumerate(val_loader)):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss = model(**batch).loss\n",
    "            val_loss += loss.item()\n",
    "            if step%100==0 and step>0:\n",
    "                print(\"Step-{},Val Loss-{}\".format(step,loss.item()))\n",
    "                break #intentionally breaking the training after 100 steps since it's going to take long to validate,feel free to comment and validate more\n",
    "        val_loss /= len(val_loader)\n",
    "    model.train()\n",
    "    break # when you train more then uncomment this, too !\n",
    "    print(f\"Epoch {epoch+1} train loss: {train_loss:.4f} val loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e14e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine_tuned_pegasus\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_pegasus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(\"fine_tuned_pegasus\")\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"fine_tuned_pegasus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764762d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SummarizationDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcdb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for step, batch in tqdm(enumerate(test_loader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        output_ids = model.generate(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], max_length=128, decoder_start_token_id=tokenizer.pad_token_id)\n",
    "        batch_predictions = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output_ids]\n",
    "        predictions.extend(batch_predictions)\n",
    "        if step==100:\n",
    "            break # breaking after generating 100 predictions.. since it's going to take long to predict on entire set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "test_df = test_df[:101]# for 100 predicitons only\n",
    "print(len(test_df))\n",
    "test_df[\"predictions\"] = predictions\n",
    "test_df.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60243742",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8551fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Article:\", test_df.iloc[0]['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540369a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Highlights:\", test_df.iloc[0]['highlights'])\n",
    "print(\"Predictions:\", test_df.iloc[0]['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f909d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ROUGE scores between the predicted summaries and the actual summaries\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(predictions, test_df[\"highlights\"].tolist(), avg=True)\n",
    "\n",
    "# Print the ROUGE scores\n",
    "print(f\"ROUGE-1: {scores['rouge-1']['f']:.4f}\")\n",
    "print(f\"ROUGE-2: {scores['rouge-2']['f']:.4f}\")\n",
    "print(f\"ROUGE-L: {scores['rouge-l']['f']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9be898",
   "metadata": {},
   "source": [
    "# Prediction from random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a40335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"fine_tuned_pegasus\")\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"fine_tuned_pegasus\")\n",
    "\n",
    "# Set the device (CPU or GPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the input text for prediction\n",
    "input_text = \"Do they Colorado Buffaloes play this weekend? If you're like us, that's the first thing you think about with each new week of the 2023 NCAA college football season. The 4-3 Buffaloes, led by NFL and MLB great Deion 'Coach Prime' Sanders, are the biggest thing to hit college football this year.Coach Prime's Buffaloes, led by Sander's stellar quarterback and son Shadeur Sanders, came into the 2023 college football season with a shocking upset win over TCU. Ever since then, the Buffaloes and Coach Prime have been ruffling feathers, winning games and turning one football fan after the next into Colorado Buffaloes fans.Keep reading for how and when to watch the next Colorado Buffaloes next game.Do the Colorado Buffaloes play this weekend?The Buffaloes have a bye week this week, which gives them plenty of time to recover from that ugly Week 7 loss to the Stanford Cardinals. The Buffaloes return to face off against the UCLA Bruins on Saturday, Oct. 28 at 7:30 p.m. ET (4:30 p.m. PT). The game will be broadcast on ABC.Next weekend's game will be held at the Rose Bowl in Pasadena, CA. The game is completely sold out, with as many as 67,000 people expected to attend live.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate predictions for the input text\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "\n",
    "# Decode the output tokens to get the predicted text\n",
    "predicted_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the predicted text\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd1528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
